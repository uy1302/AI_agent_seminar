{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\dell inspiron\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\dell inspiron\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.10.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\dell inspiron\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: gymnasium in c:\\users\\dell inspiron\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\dell inspiron\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\dell inspiron\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\dell inspiron\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dell inspiron\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\dell inspiron\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dell inspiron\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\dell inspiron\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dell inspiron\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\dell inspiron\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\dell inspiron\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dell inspiron\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\dell inspiron\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dell inspiron\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\dell inspiron\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\dell inspiron\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dell inspiron\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\dell inspiron\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gymnasium) (3.1.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\dell inspiron\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gymnasium) (0.0.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dell inspiron\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dell inspiron\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch matplotlib numpy gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as distributions\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ufal.pybox2d\n",
    "# !pip install gymnasium\n",
    "# !pip install pygame\n",
    "# !pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_env = gym.make('LunarLander-v3')\n",
    "test_env = gym.make('LunarLander-v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "# train_env.seed(SEED);\n",
    "# test_env.seed(SEED+1);\n",
    "np.random.seed(SEED);\n",
    "torch.manual_seed(SEED);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dropout = 0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, actor, critic):\n",
    "        super().__init__()\n",
    "\n",
    "        self.actor = actor\n",
    "        self.critic = critic\n",
    "\n",
    "    def forward(self, state):\n",
    "\n",
    "        action_pred = self.actor(state)\n",
    "        value_pred = self.critic(state)\n",
    "\n",
    "        return action_pred, value_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = train_env.observation_space.shape[0]\n",
    "HIDDEN_DIM = 128\n",
    "OUTPUT_DIM = test_env.action_space.n\n",
    "\n",
    "actor = MLP(INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
    "critic = MLP(INPUT_DIM, HIDDEN_DIM, 1)\n",
    "\n",
    "policy = ActorCritic(actor, critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ActorCritic(\n",
       "  (actor): MLP(\n",
       "    (net): Sequential(\n",
       "      (0): Linear(in_features=8, out_features=128, bias=True)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "      (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (4): Dropout(p=0.1, inplace=False)\n",
       "      (5): PReLU(num_parameters=1)\n",
       "      (6): Linear(in_features=128, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (critic): MLP(\n",
       "    (net): Sequential(\n",
       "      (0): Linear(in_features=8, out_features=128, bias=True)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "      (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (4): Dropout(p=0.1, inplace=False)\n",
       "      (5): PReLU(num_parameters=1)\n",
       "      (6): Linear(in_features=128, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0005\n",
    "\n",
    "optimizer = optim.Adam(policy.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_returns(rewards, discount_factor, normalize = True):\n",
    "\n",
    "    returns = []\n",
    "    R = 0\n",
    "\n",
    "    for r in reversed(rewards):\n",
    "        R = r + R * discount_factor\n",
    "        returns.insert(0, R)\n",
    "\n",
    "    returns = torch.tensor(returns)\n",
    "\n",
    "    if normalize:\n",
    "\n",
    "        returns = (returns - returns.mean()) / returns.std()\n",
    "\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_advantages(returns, values, normalize = True):\n",
    "\n",
    "    advantages = returns - values\n",
    "\n",
    "    if normalize:\n",
    "\n",
    "        advantages = (advantages - advantages.mean()) / advantages.std()\n",
    "\n",
    "    return advantages   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_policy(advantages, log_prob_actions, returns, values, optimizer):\n",
    "\n",
    "    advantages = advantages.detach()\n",
    "    returns = returns.detach()\n",
    "\n",
    "    policy_loss = - (advantages * log_prob_actions).sum()\n",
    "\n",
    "    value_loss = F.smooth_l1_loss(returns, values).sum()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    policy_loss.backward()\n",
    "    value_loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    return policy_loss.item(), value_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(env, policy):\n",
    "\n",
    "    policy.eval()\n",
    "\n",
    "    rewards = []\n",
    "    done = False\n",
    "    episode_reward = 0\n",
    "\n",
    "    state = env.reset()\n",
    "\n",
    "    while not done:\n",
    "\n",
    "        state = torch.FloatTensor(state).unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            action_pred, _ = policy(state)\n",
    "\n",
    "            action_prob = F.softmax(action_pred, dim = -1)\n",
    "\n",
    "        action = torch.argmax(action_prob, dim = -1)\n",
    "\n",
    "        state, reward, done, _ = env.step(action.item())\n",
    "\n",
    "        episode_reward += reward\n",
    "\n",
    "    return episode_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(env, policy, optimizer, discount_factor):\n",
    "\n",
    "    policy.train()\n",
    "\n",
    "    log_prob_actions = []\n",
    "    values = []\n",
    "    rewards = []\n",
    "    done = False\n",
    "    episode_reward = 0\n",
    "\n",
    "    state = env.reset()\n",
    "\n",
    "    while not done:\n",
    "\n",
    "        state = torch.FloatTensor(state).unsqueeze(0)\n",
    "\n",
    "        action_pred = actor(state)\n",
    "        value_pred = critic(state)\n",
    "\n",
    "        action_prob = F.softmax(action_pred, dim = -1)\n",
    "\n",
    "        dist = distributions.Categorical(action_prob)\n",
    "\n",
    "        action = dist.sample()\n",
    "\n",
    "        log_prob_action = dist.log_prob(action)\n",
    "\n",
    "        state, reward, done, _ = env.step(action.item())\n",
    "\n",
    "        log_prob_actions.append(log_prob_action)\n",
    "        values.append(value_pred)\n",
    "        rewards.append(reward)\n",
    "\n",
    "        episode_reward += reward\n",
    "\n",
    "    log_prob_actions = torch.cat(log_prob_actions)\n",
    "    values = torch.cat(values).squeeze(-1)\n",
    "\n",
    "    returns = calculate_returns(rewards, discount_factor)\n",
    "    advantages = calculate_advantages(returns, values)\n",
    "\n",
    "    policy_loss, value_loss = update_policy(advantages, log_prob_actions, returns, values, optimizer)\n",
    "\n",
    "    return policy_loss, value_loss, episode_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPISODES = 2000\n",
    "DISCOUNT_FACTOR = 0.99\n",
    "N_TRIALS = 25\n",
    "REWARD_THRESHOLD = 200\n",
    "PRINT_EVERY = 10\n",
    "\n",
    "train_rewards = []\n",
    "test_rewards = []\n",
    "\n",
    "for episode in range(1, MAX_EPISODES+1):\n",
    "\n",
    "    policy_loss, value_loss, train_reward = train(train_env, policy, optimizer, DISCOUNT_FACTOR)\n",
    "\n",
    "    test_reward = evaluate(test_env, policy)\n",
    "\n",
    "    train_rewards.append(train_reward)\n",
    "    test_rewards.append(test_reward)\n",
    "\n",
    "    mean_train_rewards = np.mean(train_rewards[-N_TRIALS:])\n",
    "    mean_test_rewards = np.mean(test_rewards[-N_TRIALS:])\n",
    "\n",
    "    if episode % PRINT_EVERY == 0:\n",
    "\n",
    "        print(f'| Episode: {episode:3} | Mean Train Rewards: {mean_train_rewards:7.1f} | Mean Test Rewards: {mean_test_rewards:7.1f} |')\n",
    "\n",
    "    # if mean_test_rewards >= REWARD_THRESHOLD:\n",
    "\n",
    "    #     print(f'Reached reward threshold in {episode} episodes')\n",
    "\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(test_rewards, label='Test Reward')\n",
    "plt.plot(train_rewards, label='Train Reward')\n",
    "plt.xlabel('Episode', fontsize=20)\n",
    "plt.ylabel('Reward', fontsize=20)\n",
    "plt.hlines(REWARD_THRESHOLD, 0, len(test_rewards), color='r')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory /content/drive/MyDrive/Colab Notebooks does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m MODEL_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/drive/MyDrive/Colab Notebooks/lunar_lander_policy.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMODEL_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Recreate the ActorCritic model structure\u001b[39;00m\n\u001b[0;32m      4\u001b[0m actor \u001b[38;5;241m=\u001b[39m MLP(INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:651\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[0;32m    648\u001b[0m _check_save_filelike(f)\n\u001b[0;32m    650\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m--> 651\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m    652\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)\n\u001b[0;32m    653\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:525\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[1;34m(name_or_buffer)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    524\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[1;32m--> 525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:496\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    494\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mPyTorchFileWriter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream))\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 496\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Parent directory /content/drive/MyDrive/Colab Notebooks does not exist."
     ]
    }
   ],
   "source": [
    "MODEL_PATH = \"/content/drive/MyDrive/Colab Notebooks/lunar_lander_policy.pth\"\n",
    "torch.save(policy.state_dict(), MODEL_PATH)\n",
    "# Recreate the ActorCritic model structure\n",
    "actor = MLP(INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
    "critic = MLP(INPUT_DIM, HIDDEN_DIM, 1)\n",
    "policy = ActorCritic(actor, critic)\n",
    "\n",
    "# Load the saved state dictionary into the policy model\n",
    "policy.load_state_dict(torch.load(MODEL_PATH))\n",
    "policy.eval()  # Set the model to evaluation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gym\\envs\\box2d\\lunar_lander.py:604: UserWarning: \u001b[33mWARN: You are calling render method without specifying any render mode. You can specify the render_mode at initialization, e.g. gym(\"LunarLander-v2\", render_mode=\"rgb_array\")\u001b[0m\n",
      "  gym.logger.warn(\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_9068\\3215299217.py:14: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
      "  state = torch.FloatTensor(state).unsqueeze(0)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 8 at dim 1 (got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m env \u001b[38;5;241m=\u001b[39m gym\u001b[38;5;241m.\u001b[39mmake(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLunarLander-v2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Play using the trained policy\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m \u001b[43mplay_lunar_lander\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[21], line 14\u001b[0m, in \u001b[0;36mplay_lunar_lander\u001b[1;34m(env, policy)\u001b[0m\n\u001b[0;32m     11\u001b[0m env\u001b[38;5;241m.\u001b[39mrender()\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Convert state to a PyTorch tensor\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFloatTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Get action prediction from the trained policy\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "\u001b[1;31mValueError\u001b[0m: expected sequence of length 8 at dim 1 (got 0)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def play_lunar_lander(env, policy):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        # Render the environment\n",
    "        env.render()\n",
    "\n",
    "        # Convert state to a PyTorch tensor\n",
    "        state = torch.FloatTensor(state).unsqueeze(0)\n",
    "\n",
    "        # Get action prediction from the trained policy\n",
    "        with torch.no_grad():\n",
    "            action_pred, _ = policy(state)  # Get action logits from the actor\n",
    "            action_prob = F.softmax(action_pred, dim=-1)  # Convert to probabilities\n",
    "\n",
    "        # Choose the action with the highest probability\n",
    "        action = torch.argmax(action_prob, dim=-1).item()\n",
    "\n",
    "        # Step in the environment\n",
    "        state, reward, done, _ = env.step(action)\n",
    "\n",
    "        # Accumulate the total reward\n",
    "        total_reward += reward\n",
    "\n",
    "    env.close()\n",
    "    print(f\"Total Reward: {total_reward}\")\n",
    "\n",
    "# Example usage with LunarLander-v2\n",
    "# import gym\n",
    "env = gym.make(\"LunarLander-v2\")\n",
    "\n",
    "# Play using the trained policy\n",
    "play_lunar_lander(env, policy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_19780\\3024843526.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  policy.load_state_dict(torch.load('lunar_lander_policy.pth'))\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (600, 400) to (608, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward: 263.2251290163955 Number of frames: 398\n",
      "Episode reward: 232.18414202066472 Number of frames: 307\n",
      "Episode reward: 244.2906999590402 Number of frames: 467\n",
      "Episode reward: 243.5489376627326 Number of frames: 342\n",
      "Episode reward: -70.7104461368815 Number of frames: 886\n",
      "Video saved to './videos'\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import torch\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "\n",
    "\n",
    "actor = MLP(INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
    "critic = MLP(INPUT_DIM, HIDDEN_DIM, 1)\n",
    "policy = ActorCritic(actor, critic)\n",
    "\n",
    "# Load the saved state dictionary into the policy model\n",
    "policy.load_state_dict(torch.load('lunar_lander_policy.pth'))\n",
    "policy.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Create the environment\n",
    "env = gym.make(\"LunarLander-v3\", render_mode=\"rgb_array\")\n",
    "env = RecordVideo(env, video_folder=\"./videos\", name_prefix=\"lunar_lander_test_3\")\n",
    "\n",
    "# Run the policy in the environment\n",
    "state, _ = env.reset()\n",
    "total = 0\n",
    "done = False\n",
    "frame = 0\n",
    "history = []\n",
    "\n",
    "rews=[]\n",
    "frames=[]\n",
    "success_count = 0\n",
    "filename = \"a2c.mp4\"\n",
    "with imageio.get_writer(filename, fps=30) as video:\n",
    "    for _ in range(5):\n",
    "      state, _ = env.reset()\n",
    "      total = 0\n",
    "      done = False\n",
    "      frame = 0\n",
    "      history = []\n",
    "      reward=0\n",
    "      frame_counter=0\n",
    "      while not done:\n",
    "        \n",
    "        state_tensor = torch.FloatTensor(state).unsqueeze(0)  \n",
    "        with torch.no_grad():  \n",
    "            action_pred, _ = policy(state_tensor)  \n",
    "\n",
    "        action_prob = F.softmax(action_pred, dim=-1)  \n",
    "        action = torch.argmax(action_prob, dim=-1)  \n",
    "        state, rew, done, _, _ = env.step(action.item())\n",
    "        reward+=rew\n",
    "        video.append_data(env.render())\n",
    "        frame_counter+=1\n",
    "      print('Episode reward:', reward, 'Number of frames:', frame_counter)\n",
    "env.close()\n",
    "\n",
    "print(\"Video saved to './videos'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22bee098fe0>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "def play_replay(filename=\"/content/drive/MyDrive/Colab Notebooks/replay.mp4\"):\n",
    "  mp4 = open(filename,'rb').read()\n",
    "  data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "  return HTML(\"\"\"\n",
    "  <video width=400 controls>\n",
    "        <source src=\"%s\" type=\"video/mp4\">\n",
    "  </video>\n",
    "  \"\"\" % data_url)\n",
    "\n",
    "play_replay()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
